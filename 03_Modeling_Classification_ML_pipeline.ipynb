{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ML Notebook 4: Classification\n",
    "## Regression Classification and Multi-Class Classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model 1: Regression classification using our visual feature topic matrix as features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# read our files\n",
    "train = pd.read_csv('data/SCUT-FBP5500_v2/train_bovw.zip')\n",
    "test = pd.read_csv('data/SCUT-FBP5500_v2/test_bovw.zip')    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "X_train = train.iloc[:,2:]\n",
    "y_train = train['rating']\n",
    "X_test = test.iloc[:,2:]\n",
    "y_test = test['rating']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "y_test.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2200,)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "y_pred.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2200,)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# grid search pipeline example\n",
    "# pipelines\n",
    "pipe_rf = Pipeline([('scl', StandardScaler()),\n",
    "\t\t\t('clf', RandomForestRegressor(random_state=42))])\n",
    "\n",
    "pipe_svr = Pipeline([('scl', StandardScaler()),\n",
    "\t\t\t('clf', SVR())])\n",
    "# Set grid search params\n",
    "param_range = [9, 10,20,30]\n",
    "param_range_fl = [1.0, 0.5]\n",
    "estimators = [200,250,300,350]\n",
    "\n",
    "grid_params_rf = [{'max_depth': param_range,\n",
    "        'n_estimators': estimators,\n",
    "        'min_samples_split': param_range[1:]}]\n",
    "\n",
    "grid_params_svr = [{'kernel': ['rbf'], \n",
    "        'C': param_range_fl}]\n",
    "\n",
    "# Construct grid searches\n",
    "jobs = -1\n",
    "\n",
    "gs_rf = GridSearchCV(estimator=RandomForestRegressor(random_state=42,criterion='squared_errorâ€'),\n",
    "\t\t\tparam_grid=grid_params_rf,\n",
    "\t\t\tscoring='neg_mean_squared_error',\n",
    "\t\t\tcv=5, \n",
    "\t\t\tn_jobs=jobs)\n",
    "gs_svr = GridSearchCV(estimator=SVR(),\n",
    "\t\t\tparam_grid=grid_params_svr,\n",
    "\t\t\tscoring='neg_mean_squared_error',\n",
    "\t\t\tcv=5,\n",
    "\t\t\tn_jobs=jobs)\n",
    "\n",
    "# List of pipelines for iterating through each of them\n",
    "# Removed rf do to fitting issues , gs_rf,\n",
    "grids = [gs_svr, gs_rf]\n",
    "\n",
    "# Creating a dict for our reference\n",
    "grid_dict = {0: 'Support Vector Machine', 1: 'Random Forest'} #0: 'Random Forest',\n",
    "\n",
    "grid_dict_results = {}\n",
    "\n",
    "# Fit the grid search objects\n",
    "print('Performing model optimizations...')\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "for idx, gs in enumerate(grids):\n",
    "    print('\\nEstimator: %s' % grid_dict[idx])\n",
    "    gs.fit(X_train, y_train)\n",
    "    print('Best params are : %s' % gs.best_params_)\n",
    "    # Best training data accuracy\n",
    "    print('Best training mean squared error score: %.3f' % gs.best_score_)\n",
    "    # Predict on test data with best params\n",
    "    y_pred = gs.predict(X_test)\n",
    "    # Test data accuracy of model with best params\n",
    "    acc = gs.score(X_test, y_test)\n",
    "    print('Test set mean squared error  for best params: %.3f ' % acc)\n",
    "    # Track best (highest test accuracy) model\n",
    "    grid_dict_results[grid_dict[idx]] = [gs.cv_results_, gs.best_params_, gs.best_score_, acc]\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_gs = gs\n",
    "        best_clf = idx\n",
    "print('\\nClassifier with best test set score ( mean squared error ): %s' % grid_dict[best_clf])\n",
    "\n",
    "# Save best grid search pipeline to file\n",
    "gs_dump_file = 'best_grid_search_pipeline.pkl'\n",
    "dict_dump_file = 'ml_gs_dict.pkl'\n",
    "path1 = 'data/SCUT-FBP5500_v2/' + gs_dump_file\n",
    "path2 = 'data/SCUT-FBP5500_v2/' + dict_dump_file\n",
    "with open(path1, 'wb') as f:\n",
    "    pickle.dump(best_gs, f)\n",
    "with open(path2, 'wb') as f:\n",
    "    pickle.dump(grid_dict_results, f)\n",
    "print('\\nSaved %s grid search pipeline to file: %s' % (grid_dict[best_clf], gs_dump_file))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Performing model optimizations...\n",
      "\n",
      "Estimator: Support Vector Machine\n",
      "Best params are : {'C': 1.0, 'kernel': 'rbf'}\n",
      "Best training mean squared error score: -0.331\n",
      "Test set mean squared error  for best params: -0.313 \n",
      "\n",
      "Estimator: Random Forest\n",
      "Best params are : {'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 350}\n",
      "Best training mean squared error score: -0.393\n",
      "Test set mean squared error  for best params: -0.364 \n",
      "\n",
      "Classifier with best test set score ( mean squared error ): Support Vector Machine\n",
      "\n",
      "Saved Support Vector Machine grid search pipeline to file: best_grid_search_pipeline.pkl\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# mean squared error for best model: 0.313 \n",
    "# ----------------------------------------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model 2: Multi-Class classification using all of our features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# if using google colab for outsourced processing uncomment this cell\n",
    "\n",
    "## Pandas needs to be updated on google drive to read in pickle files\n",
    "# !pip install --upgrade pandas\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/drive')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TRAINING"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# this cell calls the model\n",
    "# The model can be re-loaded at various traing stages as we save after each epcoh batch\n",
    "\n",
    "# first time we did this\n",
    "#clf = PassiveAggressiveClassifier(random_state=42, n_jobs=-1, warm_start=True)\n",
    "\n",
    "# reloading we call the pickled model from its local directory\n",
    "clf = pickle.load(open('/drive/My Drive/Milestone 2 Project/ML_data/trained_PAC_CLF_batch_0013_model.pkl', 'rb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def trainer(filename, batch_num):\n",
    "    \"\"\"\n",
    "    Helper function for training epochs. The path variable may be updated based on local storage set up.\n",
    "    \n",
    "    Params:\n",
    "    filename: the date filename e.g train_batch_000.zip\n",
    "    batch_num: This will name the exported classifier model\n",
    "    \n",
    "    Return:\n",
    "    trains the model stored in clf variable; returns nothing\n",
    "    \"\"\"\n",
    "    # read in batch\n",
    "    path = \"/drive/My Drive/Milestone 2 Project/ML_data/\" + filename \n",
    "    train = pd.read_csv(path)\n",
    "\n",
    "    # separate\n",
    "    # rounding rating because classifying\n",
    "    # skip first two columns which are rating and filename\n",
    "    X_train = train.iloc[:,2:]\n",
    "    y_train = train['rating'].round(0).astype(int)\n",
    "\n",
    "    # Classification classes are [1,2,3,4,5]\n",
    "    clf.partial_fit(X_train, y_train, classes=[1,2,3,4,5])\n",
    "\n",
    "    # Save output\n",
    "    with open(f\"/drive/My Drive/Milestone 2 Project/ML_data/trained_PAC_CLF_batch_00{batch_num}_model.pkl\", 'wb') as out:\n",
    "        pickle.dump(clf, out)\n",
    "\n",
    "    print(f\"training {filename} complete\")\n",
    "    \n",
    "    return\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer('train_batch_000.zip', 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer('train_batch_001.zip', 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer('train_batch_002.zip', 2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer('train_batch_003.zip', 3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer('train_batch_004.zip', 4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer('train_batch_005.zip', 5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer('train_batch_006.zip', 6)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer('train_batch_007.zip', 7)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer('train_batch_008.zip', 8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer('train_batch_009.zip', 9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer('train_batch_0010.zip', 10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer('train_batch_0011.zip',11)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer('train_batch_0012.zip', 12)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer('train_batch_0013.zip', 13)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TESTING"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load in the classifier that we want to test\n",
    "#clf = pickle.load(open('/drive/My Drive/Milestone 2 Project/ML_data/trained_PAC_CLF_batch_0013_model.pkl', 'rb'))\n",
    "\n",
    "\n",
    "# dictionary holder for scores\n",
    "test_scores = {}\n",
    "def testing_func(filename, ix):\n",
    "  path = '/drive/My Drive/Milestone 2 Project/ML_data/' + filename\n",
    "  test = pd.read_csv(path)\n",
    "  X_test = test.iloc[:,2:]\n",
    "  \n",
    "  # defining the rating by first rounding using numpy then cast to Integer\n",
    "  # Classification classes are [1,2,3,4,5]\n",
    "  y_test = test['rating'].astype('float').round(0).astype('int')\n",
    "\n",
    "  y_pred = clf.predict(X_test)\n",
    "  tmp_dict = {'filename':test['filename'],'rating':y_test,'pred_rating':y_pred}\n",
    "  test_scores[ix] = pd.DataFrame.from_dict(tmp_dict)\n",
    "\n",
    "  return\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "testing_func('test_batch_001.zip', 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "testing_func('test_batch_002.zip', 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "testing_func('test_batch_003.zip', 2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "testing_func('test_batch_004.zip', 3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "testing_func('test_batch_005.zip', 4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "testing_func('test_batch_006.zip', 5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "testing_func('test_batch_007.zip', 6)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "testing_func('test_batch_008.zip', 7)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save output\n",
    "# with open(f\"/drive/My Drive/Milestone 2 Project/ML_data/test_scores.pkl\", 'wb') as out:\n",
    "#  pickle.dump(test_scores,out)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# test = pickle.load(open(\"/drive/My Drive/Milestone 2 Project/ML_data/test_scores.pkl\", 'rb'))\n",
    "test_scores_df = pd.DataFrame()\n",
    "for v in test.values():\n",
    "  test_scores_df = pd.concat([test_scores_df, v])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pac_clf_accu_scr = accuracy_score(test_scores_df.rating, test_scores_df.pred_rating)\n",
    "# 0.3030769230769231\n",
    "pac_clf_accu_scr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cm = confusion_matrix(test_scores_df.rating, test_scores_df.pred_rating, labels= [1,2,3,4,5])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[1,2,3,4,5])\n",
    "disp.plot(values_format = '.1f')\n",
    "plt.title('Passive Aggressive Classifier Accuracy = 30.3%')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}