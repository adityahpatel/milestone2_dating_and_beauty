{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ML Regression Modeling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVR"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# save our files\n",
    "train = pd.read_pickle('data/SCUT-FBP5500_v2/train_df')\n",
    "test = pd.read_pickle('data/SCUT-FBP5500_v2/test_df')    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "X_train = train[['male', 'asian','bovw','PCA_1', 'PCA_2']]\n",
    "y_train = train['rating']\n",
    "X_test = test[['male', 'asian','bovw','PCA_1', 'PCA_2']]\n",
    "y_test = test['rating']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Standard scale the features so that it is easier computationally\n",
    "sc_X = StandardScaler()\n",
    "\n",
    "# train the SVR model \n",
    "# try polynomial as well\n",
    "svr_reg = SVR(kernel = 'rbf')\n",
    "# train\n",
    "\n",
    "# predict\n",
    "y_pred = svr_reg.predict(X_test)\n",
    "\n",
    "#score\n",
    "\n",
    "# plotting the line if two dimensional pca\n",
    "plt.plot(X_grid, svr_reg.predict(X_grid), color = 'black')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# random forest regression\n",
    "# Fitting Random Forest Regression to the dataset\n",
    "\n",
    "rf_reg = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "rf_reg.fit(X_train.reshape(-1,1), y_train.reshape(-1,1))\n",
    "\n",
    "y_pred = rf_reg.predict(X_test.reshape(-1,1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# grid search pipeline example\n",
    "# pipelines\n",
    "pipe_rf = Pipeline([('scl', StandardScaler()),\n",
    "\t\t\t('clf', RandomForestRegressor(random_state=42))])\n",
    "\n",
    "pipe_svr = Pipeline([('scl', StandardScaler()),\n",
    "\t\t\t('clf', SVR())])\n",
    "# Set grid search params\n",
    "param_range = [9, 10]\n",
    "param_range_fl = [1.0, 0.5]\n",
    "\n",
    "grid_params_rf = [{'clf__criterion': ['gini', 'entropy'],\n",
    "        'clf__max_depth': param_range,\n",
    "        'clf__min_samples_split': param_range[1:]}]\n",
    "\n",
    "grid_params_svr = [{'clf__kernel': ['poly', 'rbf'], \n",
    "        'clf__C': param_range_fl}]\n",
    "\n",
    "# Construct grid searches\n",
    "jobs = -1\n",
    "\n",
    "gs_rf = GridSearchCV(estimator=pipe_rf,\n",
    "\t\t\tparam_grid=grid_params_rf,\n",
    "\t\t\tscoring='accuracy',\n",
    "\t\t\tcv=5, \n",
    "\t\t\tn_jobs=jobs)\n",
    "gs_svr = GridSearchCV(estimator=pipe_svr,\n",
    "\t\t\tparam_grid=grid_params_svr,\n",
    "\t\t\tscoring='accuracy',\n",
    "\t\t\tcv=5,\n",
    "\t\t\tn_jobs=jobs)\n",
    "\n",
    "# List of pipelines for iterating through each of them\n",
    "grids = [gs_rf,gs_svr]\n",
    "\n",
    "# Creating a dict for our reference\n",
    "grid_dict = {0: 'Random Forest',\n",
    "        1: 'Support Vector Machine'}\n",
    "\n",
    "grid_dict_results = {}\n",
    "\n",
    "# Fit the grid search objects\n",
    "print('Performing model optimizations...')\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "for idx, gs in enumerate(grids):\n",
    "    print('\\nEstimator: %s' % grid_dict[idx])\n",
    "    gs.fit(X_train, y_train)\n",
    "    print('Best params are : %s' % gs.best_params_)\n",
    "    # Best training data accuracy\n",
    "    print('Best training accuracy: %.3f' % gs.best_score_)\n",
    "    # Predict on test data with best params\n",
    "    y_pred = gs.predict(X_test)\n",
    "    # Test data accuracy of model with best params\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print('Test set accuracy score for best params: %.3f ' % acc)\n",
    "    # Track best (highest test accuracy) model\n",
    "    grid_dict_results[grid_dict[idx]] = [gs.cv_results_, gs.best_params_, gs.best_score_, acc]\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_gs = gs\n",
    "        best_clf = idx\n",
    "print('\\nClassifier with best test set accuracy: %s' % grid_dict[best_clf])\n",
    "\n",
    "# Save best grid search pipeline to file\n",
    "gs_dump_file = 'best_grid_search_pipeline.pkl'\n",
    "dict_dump_file = 'ml_gs_dict.pkl'\n",
    "path1 = 'data/SCUT-FBP5500_v2/' + gs_dump_file\n",
    "path2 = 'data/SCUT-FBP5500_v2/' + dict_dump_file\n",
    "with open(path1, 'wb') as f:\n",
    "    pickle.dump(best_gs, f)\n",
    "with open(path2, 'wb') as f:\n",
    "    pickle.dump(grid_dict_results, f)\n",
    "print('\\nSaved %s grid search pipeline to file: %s' % (grid_dict[best_clf], dump_file))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Performing model optimizations...\n",
      "\n",
      "Estimator: Random Forest\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: only size-1 arrays can be converted to Python scalars\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/pipeline.py\", line 303, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\", line 730, in fit\n",
      "    return self.partial_fit(X, y, sample_weight)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\", line 766, in partial_fit\n",
      "    X = self._validate_data(X, accept_sparse=('csr', 'csc'),\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/base.py\", line 421, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 673, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/numpy/core/_asarray.py\", line 83, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/generic.py\", line 1990, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/numpy/core/_asarray.py\", line 83, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "ValueError: setting an array element with a sequence.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}